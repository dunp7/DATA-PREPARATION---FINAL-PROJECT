{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv('D:\\\\DSEB 63 - NEU\\\\Năm BA\\\\Visualization\\\\train data\\\\app_train.csv')\n",
    "app_test = pd.read_csv('D:\\\\DSEB 63 - NEU\\\\Năm BA\\\\Visualization\\\\train data\\\\app_test.csv')\n",
    "prev_app = pd.read_csv('D:\\\\DSEB 63 - NEU\\\\Năm BA\\\\Visualization\\\\train data\\\\prev_app.csv')\n",
    "pos_cash = pd.read_csv('D:\\\\DSEB 63 - NEU\\\\Năm BA\\\\Visualization\\\\train data\\\\pos_cash.csv')\n",
    "bureau = pd.read_csv('D:\\\\DSEB 63 - NEU\\\\Năm BA\\\\Visualization\\\\train data\\\\bureau_balance_merge_bureau.csv')\n",
    "ccb = pd.read_csv('D:\\\\DSEB 63 - NEU\\\\Năm BA\\\\Visualization\\\\train data\\\\credit_card_balance_final.csv')\n",
    "inp = pd.read_csv('D:\\\\DSEB 63 - NEU\\\\Năm BA\\\\Visualization\\\\train data\\\\installments_payments_final.csv').drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.rename(columns={'SK_ID_CURR_': 'SK_ID_CURR'},inplace=True)\n",
    "full_train = pd.merge(app_train, bureau, on= 'SK_ID_CURR', how = 'left')\n",
    "full_train = pd.merge(full_train,prev_app, on = 'SK_ID_CURR', how = 'left')\n",
    "full_train = pd.merge(full_train,inp, on = 'SK_ID_CURR', how = 'left')\n",
    "full_train = pd.merge(full_train,ccb, on = 'SK_ID_CURR', how = 'left')\n",
    "full_train = pd.merge(full_train,pos_cash, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_high_nulL_per(data, threshold = 70):\n",
    "    '''Func to drop col with %null > threshold (default 70)\n",
    "        Input : data_train\n",
    "    '''\n",
    "    null_check = data.isnull().sum() / data.shape[0] * 100\n",
    "    null_check = null_check.drop(null_check[null_check == 0].index).sort_values(ascending= False).reset_index()\n",
    "    drop_null_col =null_check[null_check[0] > threshold]['index'].tolist()\n",
    "    return drop_null_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(data):\n",
    "    '''Input is X_ord_trained\n",
    "        Output is all the things that train do and they is used for test\n",
    "    '''\n",
    "\n",
    "    # Fill nan\n",
    "    ### Numeric data\n",
    "    num_data = data._get_numeric_data().drop(columns = ['SK_ID_CURR','TARGET'])\n",
    "    mean_num_data = num_data.mean()\n",
    "    ### Categorical data\n",
    "    cat_data = data[[col for col in data.columns if col not in num_data.columns and col not in ['SK_ID_CURR','TARGET']]]\n",
    "    mode_cat_data = cat_data.mode().iloc[0]\n",
    "\n",
    "\n",
    "    return mean_num_data,num_data.columns ,mode_cat_data, cat_data.columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train.drop(columns = find_high_nulL_per(full_train),axis = 1,inplace=True)\n",
    "app_test.drop(columns = find_high_nulL_per(full_train),axis = 1, inplace=True)\n",
    "fill_num,num_col ,fill_cat,cat_col = fill_nan(full_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_app = pd.concat([app_train, app_test], axis = 0)\n",
    "# full_app[(full_app['TARGET'] == 0) | (full_app['TARGET'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.merge(full_app, bureau, on= 'SK_ID_CURR', how = 'left')\n",
    "full_data = pd.merge(full_data,prev_app, on = 'SK_ID_CURR', how = 'left')\n",
    "full_data = pd.merge(full_data,inp, on = 'SK_ID_CURR', how = 'left')\n",
    "full_data = pd.merge(full_data,ccb, on = 'SK_ID_CURR', how = 'left')\n",
    "full_data = pd.merge(full_data,pos_cash, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[num_col] = full_data[num_col].fillna(fill_num)\n",
    "full_data[cat_col] = full_data[cat_col].fillna(fill_cat)\n",
    "full_train[num_col] = full_train[num_col].fillna(fill_num)\n",
    "full_train[cat_col] = full_train[cat_col].fillna(fill_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME_CONTRACT_TYPE  -  ['Cash loans' 'Revolving loans']\n",
      "CODE_GENDER  -  ['F' 'M' 'XNA']\n",
      "FLAG_OWN_CAR  -  ['N' 'Y']\n",
      "FLAG_OWN_REALTY  -  ['N' 'Y']\n",
      "NAME_TYPE_SUITE  -  ['Family' 'Unaccompanied' 'Spouse, partner' 'Children' 'Other_A'\n",
      " 'Group of people' 'Other_B']\n",
      "NAME_INCOME_TYPE  -  ['State servant' 'Working' 'Pensioner' 'Commercial associate' 'Unemployed'\n",
      " 'Student' 'Businessman' 'Maternity leave']\n",
      "NAME_EDUCATION_TYPE  -  ['Higher education' 'Secondary / secondary special' 'Incomplete higher'\n",
      " 'Lower secondary' 'Academic degree']\n",
      "NAME_FAMILY_STATUS  -  ['Married' 'Civil marriage' 'Single / not married' 'Widow' 'Separated'\n",
      " 'Unknown']\n",
      "NAME_HOUSING_TYPE  -  ['House / apartment' 'Rented apartment' 'With parents'\n",
      " 'Municipal apartment' 'Office apartment' 'Co-op apartment']\n",
      "OCCUPATION_TYPE  -  ['Core staff' 'Laborers' 'Managers' 'Drivers' 'Sales staff'\n",
      " 'Cleaning staff' 'Private service staff' 'Medicine staff'\n",
      " 'Security staff' 'Accountants' 'Cooking staff' 'High skill tech staff'\n",
      " 'Low-skill Laborers' 'Realty agents' 'Secretaries' 'Waiters/barmen staff'\n",
      " 'IT staff' 'HR staff']\n",
      "WEEKDAY_APPR_PROCESS_START  -  ['MONDAY' 'WEDNESDAY' 'THURSDAY' 'SATURDAY' 'FRIDAY' 'TUESDAY' 'SUNDAY']\n",
      "ORGANIZATION_TYPE  -  ['School' 'Business Entity Type 3' 'Religion' 'Other' 'XNA' 'Electricity'\n",
      " 'Medicine' 'Self-employed' 'Transport: type 2' 'Business Entity Type 2'\n",
      " 'Construction' 'Housing' 'Kindergarten' 'Trade: type 7'\n",
      " 'Industry: type 11' 'Military' 'Services' 'Security Ministries'\n",
      " 'Transport: type 4' 'Government' 'Emergency' 'Security' 'Trade: type 2'\n",
      " 'University' 'Transport: type 3' 'Police' 'Business Entity Type 1'\n",
      " 'Postal' 'Industry: type 4' 'Agriculture' 'Culture' 'Hotel'\n",
      " 'Industry: type 7' 'Trade: type 3' 'Industry: type 3' 'Bank'\n",
      " 'Industry: type 9' 'Restaurant' 'Insurance' 'Trade: type 6'\n",
      " 'Transport: type 1' 'Industry: type 12' 'Industry: type 1'\n",
      " 'Industry: type 2' 'Trade: type 1' 'Industry: type 5' 'Industry: type 10'\n",
      " 'Legal Services' 'Advertising' 'Trade: type 5' 'Cleaning'\n",
      " 'Industry: type 13' 'Trade: type 4' 'Telecom' 'Industry: type 8'\n",
      " 'Realtor' 'Mobile' 'Industry: type 6']\n",
      "FLAG_CONTACT  -  ['Normal' 'Good' 'Bad']\n",
      "INS_ON_TIME_GRADE_  -  ['Good' 'Sub_Par' 'Par' 'Poor' 'Very_Poor']\n",
      "PAYMENT_GRADE_  -  ['Good' 'Par' 'Sub_Par' 'Poor' 'Very_Poor']\n"
     ]
    }
   ],
   "source": [
    "for i in cat_col:\n",
    "    print(f'{i}  -  {full_train[i].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13400\\2804226941.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_ord['INS_ON_TIME_GRADE_'] = X_ord['INS_ON_TIME_GRADE_'].map(ins_on_time_grade_encode)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13400\\2804226941.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_ord['PAYMENT_GRADE_'] = X_ord['PAYMENT_GRADE_'].map(ins_on_time_grade_encode)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13400\\2804226941.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_ord['FLAG_CONTACT'] = X_ord['FLAG_CONTACT'].map(ins_on_time_grade_encode)\n"
     ]
    }
   ],
   "source": [
    "# ordinal cols\n",
    "ord_col = ['INS_ON_TIME_GRADE_','PAYMENT_GRADE_','FLAG_CONTACT']\n",
    "X_ord = full_data[ord_col]\n",
    "\n",
    "ins_on_time_grade_encode = {'Good': 0, 'Par' : 1, 'Sub_Par' : 2, 'Poor' : 3,'Very_Poor': 4}\n",
    "X_ord['INS_ON_TIME_GRADE_'] = X_ord['INS_ON_TIME_GRADE_'].map(ins_on_time_grade_encode)\n",
    "\n",
    "ins_on_time_grade_encode = {'Good': 0, 'Par' : 1, 'Sub_Par' : 2, 'Poor' : 3,'Very_Poor': 4}\n",
    "X_ord['PAYMENT_GRADE_'] = X_ord['PAYMENT_GRADE_'].map(ins_on_time_grade_encode)\n",
    "\n",
    "ins_on_time_grade_encode = {'Good': 0, 'Normal' : 1, 'Bad' : 2}\n",
    "X_ord['FLAG_CONTACT'] = X_ord['FLAG_CONTACT'].map(ins_on_time_grade_encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norminal cols\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "X_one_hot = full_train[[col for col in cat_col if col not in ord_col]]\n",
    "X_one_hot = one_hot_encoder.fit(X_one_hot)\n",
    "\n",
    "\n",
    "# Fit and transform on full_train\n",
    "X_one_hot_train = one_hot_encoder.fit_transform(full_train[[col for col in cat_col if col not in ord_col]])\n",
    "X_onehot_data = one_hot_encoder.transform(full_data[[col for col in cat_col if col not in ord_col]])\n",
    "# Convert to array and concatenate with other features\n",
    "\n",
    "X_onehot_data = X_onehot_data.toarray()\n",
    "X_cat_data = pd.DataFrame(X_onehot_data)\n",
    "X_cat = pd.concat([X_ord, X_cat_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'CAR_EMPLOYED_RATIO' contains infinity.\n",
      "Column 'CAR_EMPLOYED_RATIO' contains values too large for dtype('float64').\n",
      "Column 'PAYS_TO_INS_' contains infinity.\n",
      "Column 'PAYS_TO_INS_' contains values too large for dtype('float64').\n"
     ]
    }
   ],
   "source": [
    "def check_values(column):\n",
    "    # Check for infinity\n",
    "    has_infinity = np.any(np.isinf(column))\n",
    "    \n",
    "    # Check for values too large for float64\n",
    "    too_large_values = np.any(np.abs(column) > np.finfo(np.float64).max)\n",
    "    \n",
    "    return has_infinity, too_large_values\n",
    "\n",
    "# Iterate over columns and check for infinity and large values\n",
    "def find_col(data):\n",
    "    cols = []\n",
    "    for col in data.columns:\n",
    "        has_infinity, too_large_values = check_values(data[col])\n",
    "        \n",
    "        if has_infinity:\n",
    "            print(f\"Column '{col}' contains infinity.\")\n",
    "            cols.append(col)\n",
    "\n",
    "        \n",
    "        if too_large_values:\n",
    "            print(f\"Column '{col}' contains values too large for dtype('float64').\")\n",
    "            if col not in cols:\n",
    "                cols.append(col)\n",
    "    return cols\n",
    "\n",
    "inf_col = find_col(full_train[num_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_num = full_train[num_col].drop(columns=inf_col, axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "# fit with X_train\n",
    "X_num = scaler.fit(X_num)\n",
    "\n",
    "\n",
    "# Transform the full_data\n",
    "X_num = pd.DataFrame(scaler.transform(full_data[[col for col in num_col if col not in inf_col]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set = pd.concat([X_num,X_cat],axis = 1)\n",
    "full_set['SK_ID_CURR'] = full_data['SK_ID_CURR']\n",
    "full_set['TARGET'] = full_data['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = full_set[(full_set['TARGET'] == 0) | (full_set['TARGET'] == 1)]\n",
    "test = full_set[~((full_set['TARGET'] == 0) | (full_set['TARGET'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index('SK_ID_CURR')\n",
    "train.to_csv('D:\\\\DSEB 63 - NEU\\\\Năm BA\\\\Visualization\\\\train data\\\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns='TARGET',axis = 1)\n",
    "test = test.set_index('SK_ID_CURR')\n",
    "test.to_csv('D:\\\\DSEB 63 - NEU\\\\Năm BA\\\\Visualization\\\\train data\\\\test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
